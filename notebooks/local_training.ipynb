{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Local Training Notebook for Custom LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Git\\Custom-LLM\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2025-02-22 00:03:17,533 - root - INFO - Logging configured with level: INFO\n",
            "2025-02-22 00:03:17,534 - root - INFO - Logs will be saved to: logs\\training_20250222_000317.log\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('..')  # Add parent directory to path\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "from src.model.transformer import CustomTransformer\n",
        "from src.training.trainer import Trainer\n",
        "from src.data.data_processor import DataProcessor\n",
        "import logging\n",
        "from src.utils.logging_config import setup_logging\n",
        "\n",
        "# Initialize logging\n",
        "setup_logging(log_level=logging.INFO, log_to_file=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data\n",
        "\n",
        "We'll use WikiText-2 dataset for testing, which is smaller than WikiText-103 used in the full training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load WikiText-2 dataset\n",
        "dataset = load_dataset('wikitext', 'wikitext-2-raw-v1')\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')  # Using GPT-2 tokenizer\n",
        "\n",
        "# Process training data\n",
        "train_texts = dataset['train']['text']\n",
        "val_texts = dataset['validation']['text']\n",
        "\n",
        "# Initialize data processor\n",
        "data_processor = DataProcessor(\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=512,  # Shorter sequence length for testing\n",
        "    batch_size=8  # Smaller batch size for local training\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader, val_dataloader = data_processor.prepare_data(\n",
        "    texts=train_texts,\n",
        "    split_ratio=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Initialize Model\n",
        "\n",
        "We'll create a smaller version of the model for testing purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-22 00:03:26,504 - src.model.transformer - INFO - Initializing CustomTransformer with d_model=256, n_heads=4, n_layers=4\n",
            "2025-02-22 00:03:26,609 - src.model.transformer - INFO - Created 4 transformer layers with d_ff=1024, dropout=0.1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Parameters: 28.94M\n",
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Model configuration\n",
        "model = CustomTransformer(\n",
        "    vocab_size=len(tokenizer),\n",
        "    d_model=256,  # Smaller dimension\n",
        "    n_heads=4,   # Fewer attention heads\n",
        "    n_layers=4,  # Fewer layers\n",
        "    d_ff=1024,   # Smaller feed-forward dimension\n",
        "    dropout=0.1\n",
        ")\n",
        "\n",
        "print(f'Model Parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M')\n",
        "print(f'Device: {\"cuda\" if torch.cuda.is_available() else \"cpu\"}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training Configuration\n",
        "\n",
        "Set up the trainer with appropriate hyperparameters for local testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    learning_rate=1e-4,\n",
        "    warmup_steps=100,  # Fewer warmup steps for testing\n",
        "    max_grad_norm=1.0,\n",
        "    use_wandb=False \n",
        ")\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 2  # Fewer epochs for testing\n",
        "SAVE_PATH = '../checkpoints/model_local.pt'  # Local checkpoint path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training Loop\n",
        "\n",
        "Run the training loop and monitor the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-22 00:03:26,700 - src.training.trainer - INFO - Starting training for 2 epochs\n",
            "2025-02-22 00:03:26,701 - src.training.trainer - INFO - Using device: cpu\n",
            "2025-02-22 00:03:26,702 - src.training.trainer - INFO - Training samples: 33047\n",
            "2025-02-22 00:03:26,703 - src.training.trainer - INFO - Validation samples: 3671\n",
            "2025-02-22 00:03:26,704 - src.training.trainer - INFO - Starting epoch 1/2\n",
            "Epoch 1/2:   0%|          | 0/4131 [00:00<?, ?it/s]2025-02-22 00:03:32,618 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:32,619 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:32,658 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1369\n",
            "2025-02-22 00:03:32,726 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:32,746 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:32,748 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:32,788 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1303\n",
            "2025-02-22 00:03:32,851 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:32,871 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:32,873 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:32,905 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:32,964 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:32,981 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:32,983 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:33,014 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:33,069 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:33,588 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 1/4131 [00:06<7:53:47,  6.88s/it]2025-02-22 00:03:33,605 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:33,606 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:33,642 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1086\n",
            "2025-02-22 00:03:33,695 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:33,711 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:33,712 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:33,746 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1037\n",
            "2025-02-22 00:03:33,801 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:33,817 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:33,818 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:33,849 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:33,902 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:33,918 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:33,920 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:33,953 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:34,016 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:34,531 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 2/4131 [00:07<3:53:11,  3.39s/it]2025-02-22 00:03:34,550 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:34,552 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:34,583 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0694\n",
            "2025-02-22 00:03:34,709 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:34,723 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:34,724 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:34,751 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0663\n",
            "2025-02-22 00:03:34,807 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:34,822 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:34,823 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:34,855 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:34,909 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:34,924 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:34,926 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:34,956 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:35,017 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:35,554 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 3/4131 [00:08<2:38:48,  2.31s/it]2025-02-22 00:03:35,571 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:35,572 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:35,663 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1320\n",
            "2025-02-22 00:03:35,719 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:35,734 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:35,735 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:35,766 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1262\n",
            "2025-02-22 00:03:35,820 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:35,836 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:35,838 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:35,867 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:35,919 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:35,932 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:35,933 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:35,958 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:36,008 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:36,648 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 4/4131 [00:09<2:05:47,  1.83s/it]2025-02-22 00:03:36,680 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:36,681 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:36,709 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1057\n",
            "2025-02-22 00:03:36,762 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:36,773 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:36,774 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:36,800 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1008\n",
            "2025-02-22 00:03:36,848 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:36,861 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:36,862 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:36,888 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:36,934 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:36,948 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:36,949 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:36,980 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:37,038 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:37,608 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 5/4131 [00:10<1:44:14,  1.52s/it]2025-02-22 00:03:37,626 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:37,627 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:37,658 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0799\n",
            "2025-02-22 00:03:37,712 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:37,753 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:37,754 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:37,784 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0763\n",
            "2025-02-22 00:03:37,842 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:37,857 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:37,858 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:37,889 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:37,946 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:37,965 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:37,966 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:37,999 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:38,060 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:38,590 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 6/4131 [00:11<1:31:43,  1.33s/it]2025-02-22 00:03:38,661 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:38,662 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:38,688 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1223\n",
            "2025-02-22 00:03:38,749 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:38,763 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:38,764 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:38,789 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1165\n",
            "2025-02-22 00:03:38,835 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:38,847 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:38,848 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:38,874 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:38,922 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:38,937 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:38,938 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:38,967 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:39,020 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:39,593 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 7/4131 [00:12<1:24:15,  1.23s/it]2025-02-22 00:03:39,611 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:39,612 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:39,644 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0909\n",
            "2025-02-22 00:03:39,716 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:39,732 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:39,734 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:39,761 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0864\n",
            "2025-02-22 00:03:39,821 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:39,835 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:39,836 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:39,872 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:39,928 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:39,948 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:39,949 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:39,986 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:40,047 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:40,573 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 8/4131 [00:13<1:18:51,  1.15s/it]2025-02-22 00:03:40,642 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:40,643 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:40,668 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0558\n",
            "2025-02-22 00:03:40,717 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:40,730 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:40,731 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:40,766 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0535\n",
            "2025-02-22 00:03:40,815 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:40,827 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:40,828 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:40,852 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:40,899 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:40,913 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:40,915 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:40,949 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:41,001 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:41,645 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 9/4131 [00:14<1:17:12,  1.12s/it]2025-02-22 00:03:41,669 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:41,671 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:41,729 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0646\n",
            "2025-02-22 00:03:41,780 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:41,794 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:41,795 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:41,821 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0618\n",
            "2025-02-22 00:03:41,871 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:41,885 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:41,886 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:41,911 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:41,962 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:41,979 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:41,981 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:42,013 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:42,075 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:42,574 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 10/4131 [00:15<1:13:03,  1.06s/it]2025-02-22 00:03:42,652 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:42,653 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:42,678 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1313\n",
            "2025-02-22 00:03:42,728 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:42,742 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:42,743 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:42,770 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.1247\n",
            "2025-02-22 00:03:42,835 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:42,848 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:42,850 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:42,941 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:43,011 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:43,028 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:43,029 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:43,065 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:43,130 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:43,752 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 11/4131 [00:17<1:15:26,  1.10s/it]2025-02-22 00:03:43,768 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:43,769 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:43,811 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.2453\n",
            "2025-02-22 00:03:43,860 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:43,874 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:43,875 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:43,900 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.2336\n",
            "2025-02-22 00:03:43,950 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:43,961 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:43,962 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:43,988 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:44,038 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:44,053 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:44,054 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:44,087 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:44,146 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:44,747 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 12/4131 [00:18<1:13:16,  1.07s/it]2025-02-22 00:03:44,772 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:44,773 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:44,806 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0697\n",
            "2025-02-22 00:03:44,867 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:44,885 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:44,887 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:44,941 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0664\n",
            "2025-02-22 00:03:45,000 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:45,016 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:45,017 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:45,051 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:45,119 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:45,141 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:45,142 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:45,179 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:45,244 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:45,789 - src.training.trainer - WARNING - Warning: NaN detected in model outputs\n",
            "Epoch 1/2:   0%|          | 13/4131 [00:19<1:12:44,  1.06s/it]2025-02-22 00:03:45,869 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:45,870 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:45,910 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0417\n",
            "2025-02-22 00:03:45,957 - src.model.transformer - INFO - Layer 0 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:45,970 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:45,971 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:46,004 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0398\n",
            "2025-02-22 00:03:46,058 - src.model.transformer - INFO - Layer 1 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:46,071 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:46,073 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:46,100 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:46,153 - src.model.transformer - INFO - Layer 2 stats - Mean: nan, Std: nan, Norm: nan\n",
            "2025-02-22 00:03:46,171 - src.model.attention - INFO - Attention scores shape: torch.Size([8, 4, 512, 512]), scale: 0.125\n",
            "2025-02-22 00:03:46,172 - src.model.attention - INFO - Applied mask shape: torch.Size([8, 4, 512, 512])\n",
            "2025-02-22 00:03:46,207 - src.model.attention - INFO - Attention weights stats - Mean: nan, Std: nan, Max: nan, Sparsity: 0.0000\n",
            "2025-02-22 00:03:46,268 - src.model.transformer - INFO - Layer 3 stats - Mean: nan, Std: nan, Norm: nan\n",
            "Epoch 1/2:   0%|          | 13/4131 [00:20<1:47:50,  1.57s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     logger\u001b[38;5;241m.\u001b[39maddHandler(console_handler)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAVE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# More frequent logging for debugging\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Git\\Custom-LLM\\notebooks\\..\\src\\training\\trainer.py:133\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, train_dataloader, val_dataloader, epochs, save_path, log_interval)\u001b[0m\n\u001b[0;32m    130\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Check for NaN in model outputs\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(outputs)\u001b[38;5;241m.\u001b[39many():\n",
            "File \u001b[1;32mc:\\Git\\Custom-LLM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Git\\Custom-LLM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Git\\Custom-LLM\\notebooks\\..\\src\\model\\transformer.py:83\u001b[0m, in \u001b[0;36mCustomTransformer.forward\u001b[1;34m(self, x, mask, return_attention)\u001b[0m\n\u001b[0;32m     80\u001b[0m             logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attention weights shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattention_weights\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Final linear projection to vocabulary size\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal output shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_attention:\n",
            "File \u001b[1;32mc:\\Git\\Custom-LLM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Git\\Custom-LLM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Git\\Custom-LLM\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "history = trainer.train(\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    epochs=EPOCHS,\n",
        "    save_path=SAVE_PATH,\n",
        "    log_interval=10  # More frequent logging for debugging\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analyze Results\n",
        "\n",
        "Plot training metrics to visualize the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history['train_loss'], label='Training Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot perplexity\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history['train_perplexity'], label='Training Perplexity')\n",
        "plt.plot(history['val_perplexity'], label='Validation Perplexity')\n",
        "plt.title('Training and Validation Perplexity')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
